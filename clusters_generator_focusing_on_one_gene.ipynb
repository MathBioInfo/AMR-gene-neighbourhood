{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dcfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need provide path to\n",
    "#1) RGI files\n",
    "#2) gbk files\n",
    "#3) Neighbourhood BLAST result files\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import average,complete,single,weighted,centroid\n",
    "import plotly.figure_factory as ff\n",
    "import scipy.spatial as scs\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from numpy import savetxt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib import gridspec\n",
    "import plotly.figure_factory as ff\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster, leaves_list,linkage\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy# You can use SciPy one too\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e400a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the path for .rgi files from user and load\n",
    "path = '/home/amjad/NICHEnbhd/allrgisrequired/'\n",
    "readfiles=glob.glob(os.path.join(path,\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed605ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the path for .gbk files from user and load\n",
    "path = '/home/amjad/NICHEnbhd/allgbksrequired/'\n",
    "gbkfiles=glob.glob(os.path.join(path,\"*.gbk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the required data from gbk files(entire genomes:) using biopython library #  \n",
    "def extract(infile):\n",
    "  gene_start=[]\n",
    "  gene_end=[]\n",
    "  gene_strand=[]\n",
    "  gene_name=[]\n",
    "  loc_tag=[]\n",
    "  function=[]\n",
    "  protein_seq=[]\n",
    "  contig_name=[]\n",
    "  unique=[]\n",
    "\n",
    "  for index, record in enumerate(SeqIO.parse(infile, \"genbank\")):\n",
    "    #print(\"index %i, ID = %s, length %i, with %i features\"% (index, record.id, len(record.seq), len(record.features)))\n",
    "    for i in record.features:\n",
    "        if i.type == \"CDS\" and \"gene\" in i.qualifiers:\n",
    "          locations=i.location\n",
    "          gene_start.append(locations.start)\n",
    "          gene_end.append(locations.end)\n",
    "          gene_strand.append(locations.strand)\n",
    "          loc_tag.append(i.qualifiers['locus_tag'])\n",
    "          function.append(i.qualifiers['product'])\n",
    "          protein_seq.append(str(i.qualifiers['translation']))\n",
    "          gene_name.append(i.qualifiers['gene'])\n",
    "          contig_name.append(record.id)\n",
    "        elif i.type ==\"CDS\":\n",
    "          locations=i.location\n",
    "          gene_start.append(locations.start)\n",
    "          gene_end.append(locations.end)\n",
    "          gene_strand.append(locations.strand)\n",
    "          loc_tag.append(i.qualifiers['locus_tag'])\n",
    "          function.append(i.qualifiers['product'])\n",
    "          protein_seq.append(str(i.qualifiers['translation']))\n",
    "          gene_name.append(\"UID\")\n",
    "          contig_name.append(record.id)\n",
    "          \n",
    "  salmonella_gene_frame=pd.DataFrame()\n",
    "  salmonella_gene_frame['GeneStart']=gene_start\n",
    "  salmonella_gene_frame['GeneEnd']=gene_end\n",
    "  salmonella_gene_frame['GeneStrand']=gene_strand\n",
    "  salmonella_gene_frame['Locus_Tag']=loc_tag\n",
    "  salmonella_gene_frame['GeneName']=gene_name\n",
    "  salmonella_gene_frame['Product']=function\n",
    "  salmonella_gene_frame['ProteinSequence']=protein_seq\n",
    "  salmonella_gene_frame['contig_name']=contig_name\n",
    "  \n",
    "  #print(contig_name)\n",
    "  for i in contig_name:\n",
    "    if i not in unique:\n",
    "      unique.append(i)\n",
    "\n",
    "\n",
    "  return salmonella_gene_frame,unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e0a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create groups based on contigs #\n",
    "def make_groups(frame,column):\n",
    "  group=frame.groupby(frame[column])\n",
    "  datasets = {}  \n",
    "  for groups, data in group:\n",
    "    datasets[groups] = data\n",
    "  return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845011c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating separate dictionary for all the unique AMR genes of the genome as \"key\" using the field \"Best_Hit_ARO\" #\n",
    "def createeachdict_drug(drugindex):\n",
    "\ttemp_dict={}\n",
    "\tfor j,k in datadict.items():       \n",
    "\t    temp=k[k['Best_Hit_ARO']==drugindex]\n",
    "\t    if len(temp)>0:\n",
    "\t        temp_dict[j]=temp\n",
    "\treturn temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2815ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to assign color to all and any AMR genes in the neighborhood based on CARD color codes for strict, loose and perfect hits #\n",
    "color_Dict={\"Loose\":\"#DC7633 \",\"Perfect\":\"#28B463\",\"Strict\":\"#F4D03F\"}\n",
    "def checkforRGIinneighborhood(e,genome,rgi_gene):\n",
    "    for q in range(len(e[\"GeneEnd\"])):\n",
    "        for p in range(len(datadict[genome][\"Stop\"])):\n",
    "            datadict[genome].reset_index(drop=True, inplace=True)\n",
    "            #print(e[\"GeneEnd\"][q],p)\n",
    "            if e[\"GeneEnd\"][q] == datadict[genome][\"Stop\"][p] and e[\"GeneName\"][q]==rgi_gene:\n",
    "                e[\"Genecolor\"][q]=color_Dict[datadict[genome][\"Cut_Off\"][p]]\n",
    "                                    \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afebcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to delete keys of those AMR genes who are not present in atleast 25% of the total genomes ##\n",
    "def delete_keys_lessthan_25percent_instances(dict_element):\n",
    "    total_genomes= len(gbkfiles)\n",
    "    minimum_genomes = int((total_genomes /25)*100)\n",
    "    emptykeyslist=[]\n",
    "    for i,j in dict_element.items():\n",
    "        if len(j)<=minimum_genomes:\n",
    "            emptykeyslist.append(i)\n",
    "    for i in emptykeyslist:\n",
    "        del dict_element[i]\n",
    "    return dict_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to compute neighbors of each AMR gene based on contig info ##\n",
    "def find_neighbor(rec,uname,data,number_of_genes,drug,genome,key,instancetype):\n",
    "      \n",
    "      neighbor_genes=[]\n",
    "      rec.reset_index(drop=True, inplace=True)\n",
    "      contig_flag=0\n",
    "\n",
    "      for j in range(len(rec['Start'])):\n",
    "            m=[]\n",
    "            n=[]\n",
    "            upwardgenes=[]\n",
    "            downwardgenes=[]\n",
    "            recarray=[]\n",
    "            i=rec.loc[j].Start\n",
    "            w=rec.loc[j].Stop\n",
    "            k=rec.loc[j].req_cont\n",
    "            g=number_of_genes\n",
    "\n",
    "\n",
    "            if k in uname:\n",
    "                newlist=data[k]\n",
    "                newlist.reset_index(drop=True, inplace=True)\n",
    "                for l in range(len(newlist)):\n",
    "                    if newlist['GeneStart'][l] > i and newlist['GeneEnd'][l] > w:\n",
    "                        downwardgenes.append((newlist['GeneStart'][l],newlist['GeneEnd'][l],newlist['GeneStrand'][l],newlist['Locus_Tag'][l],newlist['ProteinSequence'][l],newlist['GeneName'][l],\"#A9F1EE\",\"Not_Applicable\"))\n",
    "                    else:\n",
    "                        upwardgenes.append((newlist['GeneStart'][l],newlist['GeneEnd'][l],newlist['GeneStrand'][l],newlist['Locus_Tag'][l],newlist['ProteinSequence'][l],newlist['GeneName'][l],\"#A9F1EE\",\"Not_Applicable\"))\n",
    "                    #print(upwardgenes) \n",
    "\n",
    "                newu=pd.DataFrame(upwardgenes,columns=[\"GeneStart\",\"GeneEnd\",\"Strand\",\"Locus_Tag\",\"ProteinSequence\",\"GeneName\",\"Genecolor\",\"Gene_Cut_Off\"])\n",
    "                m=(newu.iloc[(newu['GeneStart']-i).abs().argsort()[:g+1]]).sort_values(by=\"GeneStart\")\n",
    "                #print(m)\n",
    "                newd=pd.DataFrame(downwardgenes,columns=[\"GeneStart\",\"GeneEnd\",\"Strand\",\"Locus_Tag\",\"ProteinSequence\",\"GeneName\",\"Genecolor\",\"Gene_Cut_Off\"])\n",
    "                n=(newd.iloc[(newd['GeneStart']-i).abs().argsort()[:g]]).sort_values(by=\"GeneStart\")\n",
    "                #print(n)\n",
    "\n",
    "\n",
    "                recarray.append((rec['Start'][j],rec['Stop'][j],rec['Orientation'][j],rec['Locus_Tag'][j],rec['Predicted_Protein'][j],rec['Best_Hit_ARO'][j],\"#ccccff\",rec[\"Cut_Off\"][j]))\n",
    "                o=pd.DataFrame(recarray,columns=[\"GeneStart\",\"GeneEnd\",\"Strand\",\"Locus_Tag\",\"ProteinSequence\",\"GeneName\",\"Genecolor\",\"Gene_Cut_Off\"])\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(k,genome)\n",
    "                print(\"contig does not exist----\"+\"drugclass:\"+drug)\n",
    "                print(rec['Best_Hit_ARO'][j])\n",
    "      \n",
    "      \n",
    "      if len(m)!=0 and len(n)==0:\n",
    "          m.reset_index(drop=True, inplace=True)\n",
    "          m=m.drop([len(m)-1])\n",
    "          e = pd.concat([m,o,n], ignore_index=True)\n",
    "          e.reset_index(drop=True, inplace=True)\n",
    "          neighbor_genes.append(e)\n",
    "              \n",
    "      if len(m)==0 and len(n)!=0:\n",
    "\n",
    "          m.reset_index(drop=True, inplace=True)\n",
    "          n=n.drop([len(n)-1])\n",
    "          e = pd.concat([m,o,n], ignore_index=True)\n",
    "          e.reset_index(drop=True, inplace=True)\n",
    "          neighbor_genes.append(e)\n",
    "         \n",
    "\n",
    "      if(len(m)!=0 and len(n)!=0):\n",
    "        m.reset_index(drop=True, inplace=True)\n",
    "        m=m.drop([len(m)-1])\n",
    "        e = pd.concat([m,o,n], ignore_index=True)\n",
    "        e.reset_index(drop=True, inplace=True)\n",
    "        neighbor_genes.append(e)\n",
    "            \n",
    "      return neighbor_genes,contig_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locus_generator(frame,genome_name):\n",
    "    tag=[]\n",
    "    RGI_name_array=[]\n",
    "        \n",
    "    frame.reset_index(drop=True, inplace=True)\n",
    "    for index in range(len(frame)):\n",
    "        temp_name=frame[\"Best_Hit_ARO\"][index].split(\" \")\n",
    "        if len(temp_name)>1:\n",
    "            name=(temp_name[0][0]+temp_name[1][0]+\"_\"+temp_name[2])\n",
    "            RGI_name_array.append(name)\n",
    "        else:\n",
    "            name=(temp_name[0])\n",
    "            RGI_name_array.append(name)\n",
    "            \n",
    "        tag.append(genome_name+\"(\"+name+\")\"+frame[\"Cut_Off\"][index][0]+\"_\"+str(frame[\"Best_Identities\"][index]))\n",
    "        \n",
    "    return tag,RGI_name_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7617881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get separate dicts of locus tags,protein sequences and gene names inorder to compare and write to a fasta file####\n",
    "def getrequiredgenes(frame,number_of_genes,drug):\n",
    "    temp_locus_array=[]\n",
    "    temp_protein_array=[]\n",
    "    temp_genename=[]\n",
    "    #print(drug)\n",
    "    for i in frame:\n",
    "        temp_locus_array.append(list(i['Locus_Tag']))\n",
    "        temp_protein_array.append(i['ProteinSequence'])\n",
    "        temp_genename.append((i['GeneName']))\n",
    "    \n",
    "    \n",
    "    locus_to_protein_dict={}\n",
    "    for i in frame:\n",
    "        for j in range(len(i)):\n",
    "            \n",
    "            locus_to_protein_dict[i['Locus_Tag'][j].strip()]=i['ProteinSequence'][j]\n",
    "  \n",
    "    a=temp_locus_array\n",
    "    a=list(itertools.chain.from_iterable(a))\n",
    "   \n",
    "    b=temp_protein_array\n",
    "    b=list(itertools.chain.from_iterable(b))\n",
    "   \n",
    "    c=temp_genename\n",
    "    c=list(itertools.chain.from_iterable(c))\n",
    "    \n",
    " \n",
    "    if number_of_genes==10:\n",
    "        if len(frame)>1:\n",
    "            return(a[:10]+a[-10:], b[:10]+b[-10:],c[:10]+c[-10:])## for more than one card genes in a genomes\n",
    "        else:\n",
    "            return a,b,c\n",
    "        #return(a[:5]+a[-5:], b[:5]+b[-5:],c[:5]+c[-5:])## for more than one card genes in a genomes\n",
    "    if number_of_genes==14:\n",
    "        \n",
    "        if len(frame)>1:\n",
    "            print(drug)\n",
    "            return(a[:14]+a[-14:], b[:14]+b[-14:],c[:14]+c[-14:])## for more than one card genes in a genomes\n",
    "        else:\n",
    "            return a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each rgi file(.txt) using pandas and store them in a dataframe#\n",
    "# Read RGI files but focus only on vanA gene\n",
    "dataframelist=[]\n",
    "filenames=[]\n",
    "datadict={}\n",
    "for i in sorted(readfiles): \n",
    "    dfak=pd.read_csv(i,sep=\"\\t\") # added by ak to replace '/' by '-'\n",
    "    dfak[\"Best_Hit_ARO\"] = dfak[\"Best_Hit_ARO\"].apply(lambda x: x.replace(\"/\", \"-\"))\n",
    "    #filenames.append(os.path.basename(i).split(\".\")[0])\n",
    "    dfAK=pd.DataFrame(dfak)\n",
    "    required_gene = dfAK[dfAK[\"Best_Hit_ARO\"] == 'vanA'] # here I have to tell the code to focus only on vanA gene\n",
    "    if required_gene.empty:\n",
    "        print('DataFRame does not contain the required gene')\n",
    "    else:\n",
    "        dataframelist.append(pd.DataFrame(required_gene))\n",
    "        filenames.append(os.path.basename(i).split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b705c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of dataframes with keys as filenames ###\n",
    "for i in tqdm(range(len(filenames))):\n",
    "    datadict[filenames[i]]=pd.DataFrame(dataframelist[i])\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the orientation of rgi dataframe to match the data in .gbk format to help with comparison #\n",
    "for i,j in tqdm(datadict.items()):\n",
    "    j[\"Orientation\"]=j[\"Orientation\"].replace(\"-\",\"-1\")\n",
    "    j[\"Orientation\"]=j[\"Orientation\"].replace(\"+\",\"+1\")\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .gbk file data, store the info in the sorted order in dictionaries #\n",
    "gbk_names=[]\n",
    "uniquenames=[]\n",
    "datasetslist=[]\n",
    "gbkdict={}\n",
    "uniquedict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a5021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in sorted(gbkfiles):    \n",
    "    #gbk_names.append(os.path.basename(i).split(\".\")[0])\n",
    "#for i in gbk_names:\n",
    "    #uniquenames.append(str(i))\n",
    "    #datasetslist.append(str(i))\n",
    "# I want to read gbk files that contain the gene of interest. If you want to read all the gbk files the modify the code to above\n",
    "gbk_names=filenames\n",
    "uniquenames=gbk_names\n",
    "datasetslist=gbk_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbkfiles=sorted(gbkfiles) #read the files in the sorted order\n",
    "path = '/home/amjad/NICHEnbhd/allgbksrequired/'\n",
    "ext ='.gbk'\n",
    "gbkfiles = (path + pd.Series(filenames) + ext).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gbk_names)):\n",
    "    a=gbk_names[i]\n",
    "    b=uniquenames[i]\n",
    "    gbkdict[a],uniquedict[b]=extract(gbkfiles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf815c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Locus tag column from  ['SA200015_0001'] --> SA200015_001 to help while writing to fasta file required to BLAST #\n",
    "for j,i in gbkdict.items():\n",
    "    i['Locus_Tag']=i['Locus_Tag'].apply(lambda i:str(i).replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\"))\n",
    "    i['ProteinSequence']=i['ProteinSequence'].str.strip('[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To supress the warning that arise when a single value of dataframe column is manipulated #\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58702222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each .gbk file, divides the data based on available contigs using groupby and dictionary, used to find the neighbors of same contig# \n",
    "datasetdict={}\n",
    "for i in tqdm(range(len(gbk_names))):\n",
    "    for j,k in gbkdict.items():\n",
    "        datasetdict[j]=make_groups(k,\"contig_name\")\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de884c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the union of all the AMR genes present in more than 25 percent of the total genomes #\n",
    "uniquedrugdict={}\n",
    "unionofdrugclasess=[]\n",
    "\n",
    "for j,k in tqdm(datadict.items()):\n",
    "    uniquedrugclasses=[]\n",
    "    for l in range(len(k)):\n",
    "        if k['Best_Hit_ARO'][l]  not in uniquedrugclasses:\n",
    "                uniquedrugclasses.append(k[\"Best_Hit_ARO\"][l])\n",
    "    \n",
    "    uniquedrugdict[j]=uniquedrugclasses\n",
    "    time.sleep(0.1)\n",
    "        \n",
    "for i,j in tqdm(uniquedrugdict.items()):\n",
    "    for item in j:\n",
    "        if item not in unionofdrugclasess:\n",
    "            unionofdrugclasess.append(item)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the longer AMR gene names into shorter version to make them as dictionary keys and to make it easier to visualize in gene order image#\n",
    "# Haemophilis influenzea PBP3 --> Hi_PBP3#\n",
    "\n",
    "listofdrugnames_modified=[]\n",
    "for k in unionofdrugclasess:\n",
    "    if len(k.split(\" \"))>1:\n",
    "        temp=k.split(\" \")\n",
    "        listofdrugnames_modified.append(temp[0][0]+temp[1][0]+\"_\"+temp[2])\n",
    "    else:\n",
    "\n",
    "        listofdrugnames_modified.append(k.split(\"; \")[0].split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A main dictionary of all the AMR models with all the genomes \n",
    "main_dictionary={}\n",
    "for i in tqdm(range(len(listofdrugnames_modified))):\n",
    "    main_dictionary[listofdrugnames_modified[i]]=createeachdict_drug(unionofdrugclasess[i])\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a46492",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict_multigene_instances={}\n",
    "Dict_singlegene_instances={}\n",
    "for i,j in tqdm(main_dictionary.items()):\n",
    "    temp={}\n",
    "    flag=0\n",
    "    for a,b in j.items():\n",
    "        \n",
    "        if len(b)>1:\n",
    "            flag=1\n",
    "    if flag==1:\n",
    "        Dict_multigene_instances[i]=j\n",
    "    else:\n",
    "        Dict_singlegene_instances[i]=j\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c71857",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rgi_single_occurance={}\n",
    "g={}\n",
    "for i,j in Dict_singlegene_instances.items():\n",
    "    temp={}\n",
    "    l=[]\n",
    "    deletekeylist=[]\n",
    "    for a,b in j.items():\n",
    "        if len(b)==1:\n",
    "            l.append(a)\n",
    "            b.reset_index(drop=True, inplace=True)            \n",
    "            x=make_groups(b,\"Locus_Tag\")\n",
    "            for e,f in x.items():\n",
    "                temp[e]=f\n",
    "\n",
    "    dict_rgi_single_occurance[i]=temp\n",
    "    g[i]=l\n",
    " \n",
    "for i,j in Dict_singlegene_instances.items():\n",
    "    for t in g[i]:\n",
    "        del j[t]\n",
    "        \n",
    "for i,j in dict_rgi_single_occurance.items():    \n",
    "     j.update(Dict_singlegene_instances[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4baea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "singleinstance_neighboringdict_combined_range10={}\n",
    "Single_contig_end_flag_dict={}\n",
    "for i,j in dict_rgi_single_occurance.items():\n",
    "    Dict_neighboring_genes_range10={}\n",
    "    temp_contig_flag={}\n",
    "    for k,l in j.items():\n",
    "        key=k.split(\"(\")[0]\n",
    "        temp,contigflag=find_neighbor(j[k],uniquedict[key],datasetdict[key],10,i,k,key,\"Single_Instance_Neighborhood\")\n",
    "        if len(temp)>0:\n",
    "            Dict_neighboring_genes_range10[k]=temp\n",
    "            temp_contig_flag[k]=contigflag\n",
    "    singleinstance_neighboringdict_combined_range10[i]=Dict_neighboring_genes_range10\n",
    "    Single_contig_end_flag_dict[i]=temp_contig_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0adaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to extract the locus tags, protein sequences and gene names to use to later for comparison #\n",
    "Drug_singleinstance_range_10_locus_dict10={}\n",
    "Drug_singleinstance_range_10_protein_dict10={}\n",
    "Drug_singleinstance_range_10_genename_dict10={}\n",
    "\n",
    "for i,j in singleinstance_neighboringdict_combined_range10.items():\n",
    "    locustags_dict_10={}\n",
    "    protein_dict_10={}\n",
    "    genename_dict_10={}\n",
    "    for k,l in j.items():\n",
    "        locustags_dict_10[k],protein_dict_10[k],genename_dict_10[k]=getrequiredgenes(j[k],10,i)  \n",
    "    Drug_singleinstance_range_10_locus_dict10[i]=locustags_dict_10\n",
    "    Drug_singleinstance_range_10_protein_dict10[i]=protein_dict_10\n",
    "    Drug_singleinstance_range_10_genename_dict10[i]=genename_dict_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .txt files of BLAST results and store in a dictionary ######\n",
    "filepath_single='/home/amjad/NICHEnbhd/Outputs/Single_instance/output_blast_single_instance'\n",
    "Single_instance_blastdataframelist=[]\n",
    "Single_instance_blastfilename=[]\n",
    "readfiles=glob.glob(os.path.join(filepath_single,\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75eae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in readfiles:    \n",
    "    Single_instance_blastfilename.append(os.path.basename(i).split(\".\")[0])\n",
    "    i=pd.read_csv(i,index_col = False,sep=\"\\t\", names=['query_id','sub_id','PI','len','Evalue','bitscore','qseq','sseq'])\n",
    "    Single_instance_blastdataframelist.append(i)\n",
    "temp_Single_instance_blastdatadict={}### dictionary of dataframes with keys as filenames ###\n",
    "for i in range(len(Single_instance_blastfilename)):\n",
    "    a=Single_instance_blastdataframelist[i]\n",
    "    b=Single_instance_blastfilename[i]\n",
    "    temp_Single_instance_blastdatadict[b]=pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To sort and filter only those BLAST results with more than 70 percent identity \n",
    "\n",
    "Single_instance_blastdatadict={}\n",
    "for i,j in temp_Single_instance_blastdatadict.items():\n",
    "    j=j[j[\"PI\"]>70]\n",
    "    Single_instance_blastdatadict[i]=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to normalize the bitscore values \n",
    "def normalized_bitscore(z): \n",
    "  manval=[]\n",
    "  a=z[z['query_id']==z['sub_id']]\n",
    "  manval=[]\n",
    "  a=z[z['query_id']==z['sub_id']]\n",
    "  a.reset_index(drop=True, inplace=True)\n",
    "  q={}\n",
    "  for i in range(len(a)):\n",
    "    q[a['query_id'][i]]=a['bitscore'][i]\n",
    "\n",
    "  for i in range(len(z)):\n",
    "      manval.append(round(float(z['bitscore'][i])/q[z['query_id'][i]],3))\n",
    "\n",
    "  z['normalized_bitscore']=manval\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd2179",
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_instance_drugclass_genomedict={}\n",
    "for k,l in tqdm(Drug_singleinstance_range_10_locus_dict10.items()):\n",
    "    u=Single_instance_blastdatadict[k]\n",
    "    temp_dict={}\n",
    "    for a,b in l.items():        \n",
    "        temp=[]\n",
    "        u.reset_index(drop=True, inplace=True)\n",
    "        for index in range (len(u)):\n",
    "            if  u[\"query_id\"][index] in b:\n",
    "                temp.append((u[\"query_id\"][index],u[\"sub_id\"][index],u[\"PI\"][index],u[\"bitscore\"][index]))\n",
    "                    \n",
    "        \n",
    "        temp_dict[a]=pd.DataFrame(temp,columns=[\"query_id\",\"sub_id\",\"PI\",\"bitscore\"])\n",
    "    time.sleep(0.1)  \n",
    "    Single_instance_drugclass_genomedict[k]=temp_dict\n",
    "    \n",
    "\n",
    "for i,j in tqdm(Single_instance_drugclass_genomedict.items()):\n",
    "    for a,b in j.items():\n",
    "        b=normalized_bitscore(b)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to remove BLAST entry results for same gene comparison by taking the highest bit score \n",
    "def remove_duplicates(temp):\n",
    "    df=pd.DataFrame(temp,columns=[\"query_id\",\"sub_id\",\"bitscore\"])\n",
    "    d = df.sort_values(\"bitscore\", ascending=False)\n",
    "    d = d.drop_duplicates(['query_id'])\n",
    "    d.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, l in Drug_singleinstance_range_10_locus_dict10.items():\n",
    "    for genome1 in Single_instance_drugclass_genomedict[k].keys():\n",
    "        u =Single_instance_drugclass_genomedict[k][genome1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf99f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is taking a lot of, depending on the number of genomes, (upto 6 hours) time and need to be optimized. \n",
    "single_similarity_array_dict={}\n",
    "for k,l in tqdm(Drug_singleinstance_range_10_locus_dict10.items()):\n",
    "    similarity_array=[]\n",
    "    for genome1 in tqdm(Single_instance_drugclass_genomedict[k].keys()):  \n",
    "        u=Single_instance_drugclass_genomedict[k][genome1]\n",
    "        for genome2,b in l.items():\n",
    "            temp=[]\n",
    "            sum1=0\n",
    "            sum2=0\n",
    "            u.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            for index in range (len(u)):\n",
    "                if u[\"sub_id\"][index] in b:\n",
    "                    temp.append((u[\"query_id\"][index],u[\"sub_id\"][index],u[\"normalized_bitscore\"][index]))\n",
    "                \n",
    "            tempframe=remove_duplicates(temp)\n",
    "            sum1=round(tempframe[\"bitscore\"].sum(),3)\n",
    "            \n",
    "            if Single_contig_end_flag_dict[k][genome1] ==1:\n",
    "                length_original_neighborhood=len(Drug_singleinstance_range_10_locus_dict10[k][genome1])\n",
    "                difference=length_original_neighborhood-len(tempframe)\n",
    "                sum2= sum1+(21-difference-len(tempframe))\n",
    "                \n",
    "            elif Single_contig_end_flag_dict[k][genome2]==1:\n",
    "                length_original_neighborhood=len(Drug_singleinstance_range_10_locus_dict10[k][genome2])\n",
    "                difference=length_original_neighborhood-len(tempframe)                                 \n",
    "                \n",
    "                sum2= sum1+(21-difference-len(tempframe))\n",
    "            else:\n",
    "                sum2=sum1\n",
    "                #time.sleep(0.1)\n",
    "           \n",
    "            similarity_array.append((genome1,genome2,round(sum2,3)))\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    single_similarity_array_dict[k]=similarity_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928543de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to convert the similarity matrix to symmteric matric matrix by taking the average of scores\n",
    "def converttosymmetrix(j):\n",
    "    newj=[]\n",
    "    \n",
    "    for index1 in range(len(j)):\n",
    "        \n",
    "        score1=j[index1][2]\n",
    "        for index2 in range(len(j)):\n",
    "            if j[index2][1]==j[index1][0] and j[index2][0]==j[index1][1]:\n",
    "                avg=round((j[index1][2]+j[index2][2])/2,3)\n",
    "        newj.append((j[index1][0],j[index1][1],avg))\n",
    "    return newj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fcc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to convert to symmetric matrix and store the final matrix in separate dictionaries\n",
    "# This loop is also taking a lot of time and need to be optimized. \n",
    "Single_instance_matrixframe={}\n",
    "for i,j in tqdm(single_similarity_array_dict.items()):\n",
    "    new=converttosymmetrix(j)\n",
    "    finalresult=pd.DataFrame(new,columns=[\"Query_id\",\"Sub_id\",\"normalized_bitscore\"])\n",
    "    sim_mat=pd.crosstab(index=finalresult.iloc[:,0], columns=finalresult.iloc[:,1],values=finalresult.iloc[:,2], aggfunc=lambda x: x,colnames=None)\n",
    "    Y=sim_mat.values\n",
    "    Single_instance_matrixframe[i]=sim_mat\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a distance matrix and generate UPGMA clusters \n",
    "#os.mkdir(\"Outputs/UPGMA_single_clusters\")\n",
    "save_path=\"Outputs/UPGMA_single_clusters\"\n",
    "dataarray=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3572b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy.set_link_color_palette(['r', 'g', 'y', 'm'])\n",
    "matplotlib.rcParams['lines.linewidth'] = 5\n",
    "for i,j in Single_instance_matrixframe.items(): \n",
    "    if len(j)>1:\n",
    "\n",
    "        df = pd.DataFrame(j,columns=j.keys())\n",
    "        r  = df.values\n",
    "        df = df.transform(lambda x: 1 - x/r.max() )\n",
    "        df = df.round(decimals=3)\n",
    "        Y = df.values\n",
    "        np.fill_diagonal(Y, 0)\n",
    "        Y = distance.squareform(Y)\n",
    "        fig = plt.figure(figsize=(30,5))\n",
    "        Z = hierarchy.linkage(Y, 'average')\n",
    "        R=dendrogram(Z, leaf_rotation=90, leaf_font_size=8, labels=j.keys())\n",
    "        savename=os.path.join(save_path,i+\"_.png\")\n",
    "        plt.ylabel(\"Distance between neighborhoods\")\n",
    "        plt.xlabel(\"Neighborhoods with their respective Genome IDs\")\n",
    "        plt.savefig(savename,bbox_inches='tight', dpi=100)\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
