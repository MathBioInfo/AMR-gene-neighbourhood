{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9dcfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need provide path to\n",
    "#1) RGI files\n",
    "#2) gbk files\n",
    "#3) Neighbourhood BLAST result files\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import average,complete,single,weighted,centroid\n",
    "import plotly.figure_factory as ff\n",
    "import scipy.spatial as scs\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from numpy import savetxt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib import gridspec\n",
    "import plotly.figure_factory as ff\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster, leaves_list,linkage\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy# You can use SciPy one too\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e400a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the path for .rgi files from user and load\n",
    "path = '/home/amjad/NICHEnbhd/allrgisrequired/'\n",
    "readfiles=glob.glob(os.path.join(path,\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed605ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the path for .gbk files from user and load\n",
    "path = '/home/amjad/NICHEnbhd/allgbksrequired/'\n",
    "gbkfiles=glob.glob(os.path.join(path,\"*.gbk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2961f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the required data from gbk files(entire genomes:) using biopython library #  \n",
    "def extract(infile):\n",
    "  gene_start=[]\n",
    "  gene_end=[]\n",
    "  gene_strand=[]\n",
    "  gene_name=[]\n",
    "  loc_tag=[]\n",
    "  function=[]\n",
    "  protein_seq=[]\n",
    "  contig_name=[]\n",
    "  unique=[]\n",
    "\n",
    "  for index, record in enumerate(SeqIO.parse(infile, \"genbank\")):\n",
    "    #print(\"index %i, ID = %s, length %i, with %i features\"% (index, record.id, len(record.seq), len(record.features)))\n",
    "    for i in record.features:\n",
    "        if i.type == \"CDS\" and \"gene\" in i.qualifiers:\n",
    "          locations=i.location\n",
    "          gene_start.append(locations.start)\n",
    "          gene_end.append(locations.end)\n",
    "          gene_strand.append(locations.strand)\n",
    "          loc_tag.append(i.qualifiers['locus_tag'])\n",
    "          function.append(i.qualifiers['product'])\n",
    "          protein_seq.append(str(i.qualifiers['translation']))\n",
    "          gene_name.append(i.qualifiers['gene'])\n",
    "          contig_name.append(record.id)\n",
    "        elif i.type ==\"CDS\":\n",
    "          locations=i.location\n",
    "          gene_start.append(locations.start)\n",
    "          gene_end.append(locations.end)\n",
    "          gene_strand.append(locations.strand)\n",
    "          loc_tag.append(i.qualifiers['locus_tag'])\n",
    "          function.append(i.qualifiers['product'])\n",
    "          protein_seq.append(str(i.qualifiers['translation']))\n",
    "          gene_name.append(\"UID\")\n",
    "          contig_name.append(record.id)\n",
    "          \n",
    "  salmonella_gene_frame=pd.DataFrame()\n",
    "  salmonella_gene_frame['GeneStart']=gene_start\n",
    "  salmonella_gene_frame['GeneEnd']=gene_end\n",
    "  salmonella_gene_frame['GeneStrand']=gene_strand\n",
    "  salmonella_gene_frame['Locus_Tag']=loc_tag\n",
    "  salmonella_gene_frame['GeneName']=gene_name\n",
    "  salmonella_gene_frame['Product']=function\n",
    "  salmonella_gene_frame['ProteinSequence']=protein_seq\n",
    "  salmonella_gene_frame['contig_name']=contig_name\n",
    "  \n",
    "  #print(contig_name)\n",
    "  for i in contig_name:\n",
    "    if i not in unique:\n",
    "      unique.append(i)\n",
    "\n",
    "\n",
    "  return salmonella_gene_frame,unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e0a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create groups based on contigs #\n",
    "def make_groups(frame,column):\n",
    "  group=frame.groupby(frame[column])\n",
    "  datasets = {}  \n",
    "  for groups, data in group:\n",
    "    datasets[groups] = data\n",
    "  return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "845011c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating separate dictionary for all the unique AMR genes of the genome as \"key\" using the field \"Best_Hit_ARO\" #\n",
    "def createeachdict_drug(drugindex):\n",
    "\ttemp_dict={}\n",
    "\tfor j,k in datadict.items():       \n",
    "\t    temp=k[k['Best_Hit_ARO']==drugindex]\n",
    "\t    if len(temp)>0:\n",
    "\t        temp_dict[j]=temp\n",
    "\treturn temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0afebcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to delete keys of those AMR genes who are not present in atleast 25% of the total genomes ##\n",
    "def delete_keys_lessthan_25percent_instances(dict_element):\n",
    "    total_genomes= len(gbkfiles)\n",
    "    minimum_genomes = int((total_genomes /25)*100)\n",
    "    emptykeyslist=[]\n",
    "    for i,j in dict_element.items():\n",
    "        if len(j)<=minimum_genomes:\n",
    "            emptykeyslist.append(i)\n",
    "    for i in emptykeyslist:\n",
    "        del dict_element[i]\n",
    "    return dict_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aed26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to compute neighbors of each AMR gene based on contig info ##\n",
    "def find_neighbor(rec,uname,data,number_of_genes,drug,genome,key,instancetype):\n",
    "      \n",
    "      neighbor_genes=[]\n",
    "      rec.reset_index(drop=True, inplace=True)\n",
    "      contig_flag=0\n",
    "\n",
    "      for j in range(len(rec['Start'])):\n",
    "            m=[]\n",
    "            n=[]\n",
    "            upwardgenes=[]\n",
    "            downwardgenes=[]\n",
    "            recarray=[]\n",
    "            i=rec.loc[j].Start\n",
    "            w=rec.loc[j].Stop\n",
    "            k=rec.loc[j].req_cont\n",
    "            g=number_of_genes\n",
    "\n",
    "\n",
    "            if k in uname:\n",
    "                newlist=data[k]\n",
    "                newlist.reset_index(drop=True, inplace=True)\n",
    "                for l in range(len(newlist)):\n",
    "                    if newlist['GeneStart'][l] > i and newlist['GeneEnd'][l] > w:\n",
    "                        downwardgenes.append((newlist['GeneStart'][l],newlist['GeneEnd'][l],newlist['GeneStrand'][l],newlist['Locus_Tag'][l],newlist['ProteinSequence'][l],newlist['GeneName'][l],\"#A9F1EE\",\"Not_Applicable\"))\n",
    "                    else:\n",
    "                        upwardgenes.append((newlist['GeneStart'][l],newlist['GeneEnd'][l],newlist['GeneStrand'][l],newlist['Locus_Tag'][l],newlist['ProteinSequence'][l],newlist['GeneName'][l],\"#A9F1EE\",\"Not_Applicable\"))\n",
    "                    #print(upwardgenes) \n",
    "\n",
    "                newu=pd.DataFrame(upwardgenes,columns=[\"GeneStart\",\"GeneEnd\",\"Strand\",\"Locus_Tag\",\"ProteinSequence\",\"GeneName\",\"Genecolor\",\"Gene_Cut_Off\"])\n",
    "                m=(newu.iloc[(newu['GeneStart']-i).abs().argsort()[:g+1]]).sort_values(by=\"GeneStart\")\n",
    "                #print(m)\n",
    "                newd=pd.DataFrame(downwardgenes,columns=[\"GeneStart\",\"GeneEnd\",\"Strand\",\"Locus_Tag\",\"ProteinSequence\",\"GeneName\",\"Genecolor\",\"Gene_Cut_Off\"])\n",
    "                n=(newd.iloc[(newd['GeneStart']-i).abs().argsort()[:g]]).sort_values(by=\"GeneStart\")\n",
    "                #print(n)\n",
    "\n",
    "\n",
    "                recarray.append((rec['Start'][j],rec['Stop'][j],rec['Orientation'][j],rec['Locus_Tag'][j],rec['Predicted_Protein'][j],rec['Best_Hit_ARO'][j],\"#ccccff\",rec[\"Cut_Off\"][j]))\n",
    "                o=pd.DataFrame(recarray,columns=[\"GeneStart\",\"GeneEnd\",\"Strand\",\"Locus_Tag\",\"ProteinSequence\",\"GeneName\",\"Genecolor\",\"Gene_Cut_Off\"])\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(k,genome)\n",
    "                print(\"contig does not exist----\"+\"drugclass:\"+drug)\n",
    "                print(rec['Best_Hit_ARO'][j])\n",
    "      \n",
    "      \n",
    "      if len(m)!=0 and len(n)==0:\n",
    "          m.reset_index(drop=True, inplace=True)\n",
    "          m=m.drop([len(m)-1])\n",
    "          e = pd.concat([m,o,n], ignore_index=True)\n",
    "          e.reset_index(drop=True, inplace=True)\n",
    "          neighbor_genes.append(e)\n",
    "              \n",
    "      if len(m)==0 and len(n)!=0:\n",
    "\n",
    "          m.reset_index(drop=True, inplace=True)\n",
    "          n=n.drop([len(n)-1])\n",
    "          e = pd.concat([m,o,n], ignore_index=True)\n",
    "          e.reset_index(drop=True, inplace=True)\n",
    "          neighbor_genes.append(e)\n",
    "         \n",
    "\n",
    "      if(len(m)!=0 and len(n)!=0):\n",
    "        m.reset_index(drop=True, inplace=True)\n",
    "        m=m.drop([len(m)-1])\n",
    "        e = pd.concat([m,o,n], ignore_index=True)\n",
    "        e.reset_index(drop=True, inplace=True)\n",
    "        neighbor_genes.append(e)\n",
    "            \n",
    "      return neighbor_genes,contig_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93ae4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locus_generator(frame,genome_name):\n",
    "    tag=[]\n",
    "    RGI_name_array=[]\n",
    "        \n",
    "    frame.reset_index(drop=True, inplace=True)\n",
    "    for index in range(len(frame)):\n",
    "        temp_name=frame[\"Best_Hit_ARO\"][index].split(\" \")\n",
    "        if len(temp_name)>1:\n",
    "            name=(temp_name[0][0]+temp_name[1][0]+\"_\"+temp_name[2])\n",
    "            RGI_name_array.append(name)\n",
    "        else:\n",
    "            name=(temp_name[0])\n",
    "            RGI_name_array.append(name)\n",
    "            \n",
    "        tag.append(genome_name+\"(\"+name+\")\"+frame[\"Cut_Off\"][index][0]+\"_\"+str(frame[\"Best_Identities\"][index]))\n",
    "        \n",
    "    return tag,RGI_name_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7617881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get separate dicts of locus tags,protein sequences and gene names inorder to compare and write to a fasta file####\n",
    "def getrequiredgenes(frame,number_of_genes,drug):\n",
    "    temp_locus_array=[]\n",
    "    temp_protein_array=[]\n",
    "    temp_genename=[]\n",
    "    #print(drug)\n",
    "    for i in frame:\n",
    "        temp_locus_array.append(list(i['Locus_Tag']))\n",
    "        temp_protein_array.append(i['ProteinSequence'])\n",
    "        temp_genename.append((i['GeneName']))\n",
    "    \n",
    "    \n",
    "    locus_to_protein_dict={}\n",
    "    for i in frame:\n",
    "        for j in range(len(i)):\n",
    "            \n",
    "            locus_to_protein_dict[i['Locus_Tag'][j].strip()]=i['ProteinSequence'][j]\n",
    "  \n",
    "    a=temp_locus_array\n",
    "    a=list(itertools.chain.from_iterable(a))\n",
    "   \n",
    "    b=temp_protein_array\n",
    "    b=list(itertools.chain.from_iterable(b))\n",
    "   \n",
    "    c=temp_genename\n",
    "    c=list(itertools.chain.from_iterable(c))\n",
    "    \n",
    " \n",
    "    if number_of_genes==10:\n",
    "        if len(frame)>1:\n",
    "            return(a[:10]+a[-10:], b[:10]+b[-10:],c[:10]+c[-10:])## for more than one card genes in a genomes\n",
    "        else:\n",
    "            return a,b,c\n",
    "        #return(a[:5]+a[-5:], b[:5]+b[-5:],c[:5]+c[-5:])## for more than one card genes in a genomes\n",
    "    if number_of_genes==14:\n",
    "        \n",
    "        if len(frame)>1:\n",
    "            print(drug)\n",
    "            return(a[:14]+a[-14:], b[:14]+b[-14:],c[:14]+c[-14:])## for more than one card genes in a genomes\n",
    "        else:\n",
    "            return a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2644eb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n",
      "DataFRame does not contain: tetM\n"
     ]
    }
   ],
   "source": [
    "# Read each rgi file(.txt) using pandas and store them in a dataframe#\n",
    "# Read RGI files but focus only on vanA gene\n",
    "dataframelist=[]\n",
    "filenames=[]\n",
    "datadict={}\n",
    "gene_of_interest='tetM' # the AMR gene we are interested in\n",
    "for i in sorted(readfiles): \n",
    "    dfak=pd.read_csv(i,sep=\"\\t\") # added by ak to replace '/' by '-'\n",
    "    dfak[\"Best_Hit_ARO\"] = dfak[\"Best_Hit_ARO\"].apply(lambda x: x.replace(\"/\", \"-\"))\n",
    "    #filenames.append(os.path.basename(i).split(\".\")[0])\n",
    "    dfAK=pd.DataFrame(dfak)\n",
    "    required_gene_frame = dfAK[dfAK[\"Best_Hit_ARO\"] == gene_of_interest]\n",
    "    if required_gene_frame.empty:\n",
    "        #pass\n",
    "        print('DataFRame does not contain:', gene_of_interest)\n",
    "        \n",
    "    else:\n",
    "        dataframelist.append(pd.DataFrame(required_gene_frame))\n",
    "        filenames.append(os.path.basename(i).split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64ff3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9b705c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 783/783 [01:18<00:00,  9.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of dataframes with keys as filenames ###\n",
    "for i in tqdm(range(len(filenames))):\n",
    "    datadict[filenames[i]]=pd.DataFrame(dataframelist[i])\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7b0fa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 783/783 [01:19<00:00,  9.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Replacing the orientation of rgi dataframe to match the data in .gbk format to help with comparison #\n",
    "for i,j in tqdm(datadict.items()):\n",
    "    j[\"Orientation\"]=j[\"Orientation\"].replace(\"-\",\"-1\")\n",
    "    j[\"Orientation\"]=j[\"Orientation\"].replace(\"+\",\"+1\")\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "363ae370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding two new columns 1> Modified Locus tag and 2> contig to extract the right neighbors #\n",
    "for k,v in datadict.items():\n",
    "    newcon=[]\n",
    "    for i in v[\"Contig\"]:\n",
    "        head,sep,tail=i.partition(\"_\")\n",
    "        newcon.append(head)\n",
    "    v['req_cont']=newcon    #adding a new column \"req_cont\" into dataframe\n",
    "    v['Locus_Tag'],v[\"Best_Hit_ARO\"]=locus_generator(v,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d61b9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .gbk file data, store the info in the sorted order in dictionaries #\n",
    "gbk_names=[]\n",
    "uniquenames=[]\n",
    "datasetslist=[]\n",
    "gbkdict={}\n",
    "uniquedict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59a5021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in sorted(gbkfiles):    \n",
    "    #gbk_names.append(os.path.basename(i).split(\".\")[0])\n",
    "#for i in gbk_names:\n",
    "    #uniquenames.append(str(i))\n",
    "    #datasetslist.append(str(i))\n",
    "# I want to read gbk files that contain the gene of interest. If you want to read all the gbk files the modify the code to above\n",
    "gbk_names=filenames\n",
    "uniquenames=gbk_names\n",
    "datasetslist=gbk_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7efc407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbkfiles=sorted(gbkfiles) #read the files in the sorted order\n",
    "path = '/home/amjad/NICHEnbhd/allgbksrequired/'\n",
    "ext ='.gbk'\n",
    "gbkfiles = (path + pd.Series(filenames) + ext).tolist()\n",
    "gbkfiles=sorted(gbkfiles) #read the files in the sorted order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gbk_names)):\n",
    "    a=gbk_names[i]\n",
    "    b=uniquenames[i]\n",
    "    gbkdict[a],uniquedict[b]=extract(gbkfiles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf815c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Locus tag column from  ['SA200015_0001'] --> SA200015_001 to help while writing to fasta file required to BLAST #\n",
    "for j,i in gbkdict.items():\n",
    "    i['Locus_Tag']=i['Locus_Tag'].apply(lambda i:str(i).replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\"))\n",
    "    i['ProteinSequence']=i['ProteinSequence'].str.strip('[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To supress the warning that arise when a single value of dataframe column is manipulated #\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51167f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The block that causes the chained assignment error #\n",
    "\n",
    "for i,j in gbkdict.items():\n",
    "    for value in range(len(j[\"GeneName\"])):\n",
    "        if isinstance(j[\"GeneName\"].iloc[value], list):\n",
    "            j[\"GeneName\"].iloc[value] = j[\"GeneName\"].iloc[value][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58702222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each .gbk file, divides the data based on available contigs using groupby and dictionary, used to find the neighbors of same contig# \n",
    "datasetdict={}\n",
    "for i in tqdm(range(len(gbk_names))):\n",
    "    for j,k in gbkdict.items():\n",
    "        datasetdict[j]=make_groups(k,\"contig_name\")\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de884c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the union of all the AMR genes present in more than 25 percent of the total genomes #\n",
    "uniquedrugdict={}\n",
    "unionofdrugclasess=[]\n",
    "\n",
    "for j,k in tqdm(datadict.items()):\n",
    "    uniquedrugclasses=[]\n",
    "    for l in range(len(k)):\n",
    "        if k['Best_Hit_ARO'][l]  not in uniquedrugclasses:\n",
    "                uniquedrugclasses.append(k[\"Best_Hit_ARO\"][l])\n",
    "    \n",
    "    uniquedrugdict[j]=uniquedrugclasses\n",
    "    time.sleep(0.1)\n",
    "        \n",
    "for i,j in tqdm(uniquedrugdict.items()):\n",
    "    for item in j:\n",
    "        if item not in unionofdrugclasess:\n",
    "            unionofdrugclasess.append(item)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the longer AMR gene names into shorter version to make them as dictionary keys and to make it easier to visualize in gene order image#\n",
    "# Haemophilis influenzea PBP3 --> Hi_PBP3#\n",
    "\n",
    "listofdrugnames_modified=[]\n",
    "for k in unionofdrugclasess:\n",
    "    if len(k.split(\" \"))>1:\n",
    "        temp=k.split(\" \")\n",
    "        listofdrugnames_modified.append(temp[0][0]+temp[1][0]+\"_\"+temp[2])\n",
    "    else:\n",
    "\n",
    "        listofdrugnames_modified.append(k.split(\"; \")[0].split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A main dictionary of all the AMR models with all the genomes \n",
    "main_dictionary={}\n",
    "for i in tqdm(range(len(listofdrugnames_modified))):\n",
    "    main_dictionary[listofdrugnames_modified[i]]=createeachdict_drug(unionofdrugclasess[i])\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a46492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the AMR genes into single instance and multiple instance #\n",
    "Dict_multigene_instances={}\n",
    "Dict_singlegene_instances={}\n",
    "for i,j in tqdm(main_dictionary.items()):\n",
    "    temp={}\n",
    "    flag=0\n",
    "    for a,b in j.items():\n",
    "        \n",
    "        if len(b)>1:\n",
    "            flag=1\n",
    "    if flag==1:\n",
    "        Dict_multigene_instances[i]=j\n",
    "    else:\n",
    "        Dict_singlegene_instances[i]=j\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c71857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get one to one genome comparisons when there are multiple instances and divide the frames based on locus tags  #\n",
    "dict_rgi_multiple_occurance={}\n",
    "g={}\n",
    "for i,j in Dict_multigene_instances.items():\n",
    "    temp={}\n",
    "    l=[]\n",
    "    deletekeylist=[]\n",
    "    for a,b in j.items():\n",
    "        if len(b)>1 or len(b)==1:\n",
    "            l.append(a)\n",
    "            b.reset_index(drop=True, inplace=True)            \n",
    "            x=make_groups(b,\"Locus_Tag\")\n",
    "            for e,f in x.items():\n",
    "                temp[e]=f\n",
    "\n",
    "    dict_rgi_multiple_occurance[i]=temp\n",
    "    g[i]=l\n",
    " \n",
    "for i,j in Dict_multigene_instances.items():\n",
    "    for t in g[i]:\n",
    "        del j[t]\n",
    "        \n",
    "for i,j in dict_rgi_multiple_occurance.items():    \n",
    "     j.update(Dict_multigene_instances[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4baea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multipleinstance_neighboringdict_combined_range_10={}\n",
    "multiple_contig_end_flag_dict={}\n",
    "for i,j in dict_rgi_multiple_occurance.items():\n",
    "    Dict_neighboring_genes_range10={}\n",
    "    temp_contig_flag={}\n",
    "    for k,l in j.items():\n",
    "        key=k.split(\"(\")[0]\n",
    "        temp,contigflag=find_neighbor(j[k],uniquedict[key],datasetdict[key],10,i,k,key,\"Multiple_Instance_Neighborhood\")\n",
    "        if len(temp)>0:\n",
    "            Dict_neighboring_genes_range10[key]=temp\n",
    "            temp_contig_flag[key]=contigflag\n",
    "    multipleinstance_neighboringdict_combined_range_10[i]=Dict_neighboring_genes_range10\n",
    "    multiple_contig_end_flag_dict[i]=temp_contig_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0adaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to extract the locus tags, protein sequences and gene names to use to later for comparison #\n",
    "Drug_multiple_instance_range_10_locus_dict10={}\n",
    "Drug_multiple_instance_range_10_protein_dict10={}\n",
    "Drug_multiple_instance_range_10_genename_dict10={}\n",
    "\n",
    "for i,j in multipleinstance_neighboringdict_combined_range_10.items():\n",
    "\n",
    "    locustags_dict_10={}\n",
    "    protein_dict_10={}\n",
    "    genename_dict_10={}\n",
    "    for k,l in j.items():\n",
    "\n",
    "        locustags_dict_10[k],protein_dict_10[k],genename_dict_10[k]=getrequiredgenes(j[k],10,i)\n",
    "    #print(len(locustags_dict_10),len(protein_dict_10),len(genename_dict_10))  \n",
    "    Drug_multiple_instance_range_10_locus_dict10[i]=locustags_dict_10\n",
    "    Drug_multiple_instance_range_10_protein_dict10[i]=protein_dict_10\n",
    "    Drug_multiple_instance_range_10_genename_dict10[i]=genename_dict_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .txt files of BLAST results and store in a dictionary ######\n",
    "#filepath_single='/home/amjad/NICHEnbhd/Outputs/Single_instance/output_blast_single_instance'\n",
    "#Single_instance_blastdataframelist=[]\n",
    "#Single_instance_blastfilename=[]\n",
    "#readfiles=glob.glob(os.path.join(filepath_single,\"*.txt\"))\n",
    "filename = gene_of_interest+'.txt'\n",
    "#print(filename)\n",
    "# Read the .txt files of BLAST results and store in a dictionary ######\n",
    "filepath_single='/home/amjad/NICHEnbhd/Outputs/Multiple_instance/output_blast_multiple_instance/'+filename\n",
    "print(filepath_single)\n",
    "#Single_instance_blastdataframelist=[]\n",
    "#Single_instance_blastfilename=[]\n",
    "readfiles=glob.glob(os.path.join(filepath_single)) #Change this line\n",
    "if readfiles==[filepath_single]:\n",
    "    print(filename, \"located.\")\n",
    "    \n",
    "else:\n",
    "    print(\"The file \", filename, \"does not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75eae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multiple_instance_blastdataframelist=[]\n",
    "Multiple_instance_blastfilename=[]\n",
    "for i in readfiles:\n",
    "    Multiple_instance_blastfilename.append(os.path.basename(i).split(\".\")[0])\n",
    "    i=pd.read_csv(i,index_col = False,sep=\"\\t\", names=['query_id','sub_id','PI','len','Evalue','bitscore','qseq','sseq'])\n",
    "    #i=pd.read_csv(i,index_col = False,sep=\"\\t\")\n",
    "    Multiple_instance_blastdataframelist.append(i)\n",
    "\n",
    "temp_Multiple_instance_blastdatadict={}### dictionary of dataframes with keys as filenames ###\n",
    "for i in range(len(Multiple_instance_blastfilename)):\n",
    "    a=Multiple_instance_blastdataframelist[i]\n",
    "    b=Multiple_instance_blastfilename[i]\n",
    "    temp_Multiple_instance_blastdatadict[b]=pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute if only there are multiple instance AMR gene models #\n",
    "\n",
    "if len(temp_Multiple_instance_blastdatadict.keys())>0:\n",
    "\n",
    "    Multiple_instance_blastdatadict={}\n",
    "    for i,j in temp_Multiple_instance_blastdatadict.items():\n",
    "        j=j[j[\"PI\"]>70]\n",
    "        j = j.reset_index().drop_duplicates(subset=['query_id','sub_id','bitscore'],keep='first').set_index('index')\n",
    "        Multiple_instance_blastdatadict[i]=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to normalize the bitscore values \n",
    "def normalized_bitscore(z): \n",
    "  manval=[]\n",
    "  a=z[z['query_id']==z['sub_id']]\n",
    "  manval=[]\n",
    "  a=z[z['query_id']==z['sub_id']]\n",
    "  a.reset_index(drop=True, inplace=True)\n",
    "  q={}\n",
    "  for i in range(len(a)):\n",
    "    q[a['query_id'][i]]=a['bitscore'][i]\n",
    "\n",
    "  for i in range(len(z)):\n",
    "      manval.append(round(float(z['bitscore'][i])/q[z['query_id'][i]],3))\n",
    "\n",
    "  z['normalized_bitscore']=manval\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd2179",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Divide the mixed BLAST results into their respective AMR gene models and genomes \n",
    "multiple_instance_drugclass_genomedict={}\n",
    "for k,l in tqdm(Drug_multiple_instance_range_10_locus_dict10.items()):\n",
    "    u=Multiple_instance_blastdatadict[k]\n",
    "    temp_dict={} \n",
    "    for a,b in l.items():#          \n",
    "        temp=[]\n",
    "        u.reset_index(drop=True, inplace=True)\n",
    "        for index in range (len(u)):\n",
    "            if  u[\"query_id\"][index] in b:\n",
    "                temp.append((u[\"query_id\"][index],u[\"sub_id\"][index],u[\"PI\"][index],u[\"bitscore\"][index]))\n",
    "                        \n",
    "            #frame=pd.DataFrame(temp,columns=[\"query_id\",\"sub_id\",\"PI\",\"bitscore\"])\n",
    "        temp_dict[a]=pd.DataFrame(temp,columns=[\"query_id\",\"sub_id\",\"PI\",\"bitscore\"])\n",
    "    time.sleep(0.1)  \n",
    "    multiple_instance_drugclass_genomedict[k]=temp_dict\n",
    "\n",
    "# using the function and normalizing \n",
    "for i,j in tqdm(multiple_instance_drugclass_genomedict.items()):\n",
    "    for a,b in j.items():\n",
    "        b=normalized_bitscore(b)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to remove BLAST entry results for same gene comparison by taking the highest bit score \n",
    "def remove_duplicates(temp):\n",
    "    df=pd.DataFrame(temp,columns=[\"query_id\",\"sub_id\",\"bitscore\"])\n",
    "    d = df.sort_values(\"bitscore\", ascending=False)\n",
    "    d = d.drop_duplicates(['query_id'])\n",
    "    d.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf99f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is taking a lot of, depending on the number of genomes, (upto 6 hours) time and need to be optimized. \n",
    " # For each gene model compare the genomes and generate a similarity matrix #\n",
    "multiple_similarity_array_dict={}\n",
    "for k,l in tqdm(Drug_multiple_instance_range_10_locus_dict10.items()):\n",
    "    similarity_array=[]\n",
    "    for genome1 in tqdm(multiple_instance_drugclass_genomedict[k].keys()):  \n",
    "        u=multiple_instance_drugclass_genomedict[k][genome1]\n",
    "        for genome2,b in l.items():\n",
    "            temp=[]\n",
    "            sum1=0\n",
    "            sum2=0\n",
    "            u.reset_index(drop=True, inplace=True)\n",
    "            for index in range (len(u)):\n",
    "                if u[\"sub_id\"][index] in b:\n",
    "                    temp.append((u[\"query_id\"][index],u[\"sub_id\"][index],u[\"normalized_bitscore\"][index]))\n",
    "\n",
    "            tempframe=remove_duplicates(temp)\n",
    "            sum1=round(tempframe[\"bitscore\"].sum(),3)\n",
    "                \n",
    "            if multiple_contig_end_flag_dict[k][genome1] ==1:\n",
    "                length_original_neighborhood=len(Drug_multiple_instance_range_10_locus_dict10[k][genome1])\n",
    "                difference=length_original_neighborhood-len(tempframe)\n",
    "                sum2= sum1+(21-difference-len(tempframe))\n",
    "                    \n",
    "            elif multiple_contig_end_flag_dict[k][genome2]==1:\n",
    "                length_original_neighborhood=len(Drug_multiple_instance_range_10_locus_dict10[k][genome2])\n",
    "                difference=length_original_neighborhood-len(tempframe)                                 \n",
    "                    \n",
    "                sum2= sum1+(21-difference-len(tempframe))\n",
    "            else:\n",
    "                sum2=sum1\n",
    "               \n",
    "            similarity_array.append((genome1,genome2,round(sum1,3)))\n",
    "            time.sleep(0.1)\n",
    "    multiple_similarity_array_dict[k]=similarity_array\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928543de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to convert the similarity matrix to symmteric matric matrix by taking the average of scores\n",
    "def converttosymmetrix(j):\n",
    "    newj=[]\n",
    "    \n",
    "    for index1 in range(len(j)):\n",
    "        \n",
    "        score1=j[index1][2]\n",
    "        for index2 in range(len(j)):\n",
    "            if j[index2][1]==j[index1][0] and j[index2][0]==j[index1][1]:\n",
    "                avg=round((j[index1][2]+j[index2][2])/2,3)\n",
    "        newj.append((j[index1][0],j[index1][1],avg))\n",
    "    return newj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fcc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to convert to symmetric matrix and store the final matrix in separate dictionaries\n",
    "# This loop is also taking a lot of time and need to be optimized. \n",
    "multiple_instance_matrixframe={}\n",
    "for i,j in multiple_similarity_array_dict.items():\n",
    "    new=converttosymmetrix(j)\n",
    "    finalresult=pd.DataFrame(new,columns=[\"Query_id\",\"Sub_id\",\"normalized_bitscore\"])\n",
    "    sim_mat=pd.crosstab(index=finalresult.iloc[:,0], columns=finalresult.iloc[:,1],values=finalresult.iloc[:,2], aggfunc=lambda x: x,colnames=None)\n",
    "    Y=sim_mat.values\n",
    "    multiple_instance_matrixframe[i]=sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a distance matrix and generate UPGMA clusters \n",
    "#os.mkdir(\"Outputs/UPGMA_multiple_clusters\")\n",
    "save_path=\"Outputs/UPGMA_multiple_clusters\"\n",
    "dataarray=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3572b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy.set_link_color_palette(['r', 'g', 'y', 'm'])\n",
    "matplotlib.rcParams['lines.linewidth'] = 5\n",
    "for i,j in multiple_instance_matrixframe.items(): \n",
    "    if len(j)>1:\n",
    "\n",
    "        df = pd.DataFrame(j,columns=j.keys())\n",
    "        r  = df.values\n",
    "        df = df.transform(lambda x: 1 - x/r.max() )\n",
    "        df = df.round(decimals=3)\n",
    "        Y = df.values\n",
    "        np.fill_diagonal(Y, 0)\n",
    "        Y = distance.squareform(Y)\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        Z = hierarchy.linkage(Y, 'average')\n",
    "        dendrogram(Z, leaf_rotation=90, leaf_font_size=8, labels=j.keys())\n",
    "        savename=os.path.join(save_path,i+\"_.png\")\n",
    "        plt.ylabel(\"Distance between neighborhoods\")\n",
    "        plt.xlabel(\"Neighborhoods with their respective Genome IDs\")\n",
    "        plt.savefig(savename,bbox_inches='tight', dpi=100)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30236e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e120ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multiple_instance_matrixframe_tetM_mltpl.pkl', 'wb') as f:\n",
    "    pickle.dump(multiple_instance_matrixframe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multiple_instance_matrixframe_tetM_mltpl.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25335e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy.set_link_color_palette(['r', 'g', 'y', 'm'])\n",
    "matplotlib.rcParams['lines.linewidth'] = 2\n",
    "for i,j in loaded_dict.items(): \n",
    "    if len(j)>1:\n",
    "        df = pd.DataFrame(j,columns=j.keys())\n",
    "        r  = df.values\n",
    "        df = df.transform(lambda x: 1 - x/r.max() )\n",
    "        df = df.round(decimals=3)\n",
    "        Y = df.values\n",
    "        np.fill_diagonal(Y, 0)\n",
    "        Y = distance.squareform(Y)\n",
    "        fig = plt.figure(figsize=(90,30))\n",
    "        Z = hierarchy.linkage(Y, 'average')\n",
    "        R=dendrogram(Z, leaf_rotation=90, leaf_font_size=8, labels=j.keys())\n",
    "        savename= i+\"_mltpl.png\"\n",
    "        plt.ylabel(\"Distance between neighborhoods\", fontsize=48)\n",
    "        plt.xlabel(\"Neighborhoods with their respective Genome IDs\", fontsize=48)\n",
    "        plt.savefig(savename,bbox_inches='tight', dpi=180)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab680dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
